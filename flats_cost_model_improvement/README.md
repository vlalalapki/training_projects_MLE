# Улучшение baseline-модели
 
## Описание проекта

Общая цель работы - Улучшить алгоритм для оценки рыночной стоимости квартиры по её характеристикам.

В данном проекте нужно оптимизировать подход, основываясь на первоначально построенном решении и настроенном пайплайне данных. Основная цель — сделать процесс воспроизводимым и улучшить ключевые модельные метрики, которые влияют на бизнес-показатели компании, в частности, на увеличение количества успешных сделок. 

Существующий MPV алгоритм прогнозирования стоимости требует доработки.
Нам нужно улучшить основную метрику проекта, которая влияет на точность предсказаний стоимости недвижимости и, как следствие, на количество успешных сделок на маркетплейсе. В процессе работы задокументировать все эксперименты, используя MLflow, — это позволит отслеживать изменения в метриках и вносимые улучшения.
Все успешные версии моделей будут зарегистрированы в соответствующем реестре MLflow, чтобы мы могли их отслеживать, сравнивать и использовать впоследствии.

## Используемые технологии

- база данных PostgreSQL с данными для обучения,
- база данных PostgreSQL с данными для MLflow,
- объектное хранилище для MLflow,
- сервисы MLflow (Tracking Server и Model Registry),
- основные библиотеки для работы с проектом:
    * mlflow
    * sklearn
    * catboost 
    * mlxtend
    * autofeat
    * optuna
    * pandas


## Запуск и воспроизведение 

Для запуска проекта необходимо клонировать репозиторий, желательно, установить окружение и его зависимости из файла requirements.txt:

```sh
git clone https://github.com/vlalalapki/training_projects_MLE
cd training_projects_MLE/flats_cost_model_improvement

#установка виртуального окружения 
sudo apt-get install python3.10-venv
python3.10 -m venv .venv_project_name

#активация окружения и установка зависимостей
source .venv_project_name/bin/activate
pip install -r requirements.txt
```

## Руководство по проекту 
### Этап 1. Разворачивание MLflow и регистрация модели

На этом этапе проекта мы разворачиваем сервисы MLflow Tracking Server и MLflow Model Registry, используя базу данных PostgreSQL и объектное хранилище S3 в Yandex Cloud.
Настройки доступа к PostgreSQL и Yandex Cloud необходимо указать в файле .env в корне проекта.
Далее для развертывания MLflow необходимо запустить [скрипт](mlflow_server/run_mlflow.sh) через терминал:

```sh
sh mlflow_server/run_mlflow.sh
```

Далее на этом этапе была подгружена baseline модель из предыдущего проекта и зарегистрирована вместе с метриками и параметрами в MLflow Model Registry.<br>
Эти шаги можно найти в [mlflow_server/log_and_regist_past_results.ipynb](mlflow_server/log_and_regist_past_results.ipynb)

**Последующие этапы проекта выполнены в [model_improvement/model_improvement.ipynb](model_improvement/model_improvement.ipynb)**

### Этап 2: Проведение EDA

На этом этапе сделаны следующие шаги:
- Загружены данные в Jupyter Notebook. Проведена проверка их целостности и полноты для данного проекта.
- Визуализированы данные, распределение признаков, взаимодействие признаков и целевой переменной с помощью статистических методов и визуализации.
- По полученным данным сделаны [выводы](model_improvement/artif_eda/conclusions.md) для использования в последующих этапах проекта
- Результаты EDA залогированы в MLflow в качестве артефактов

### Этап 3: Генерация признаков и обучение модели

На данном этапе осуществлено следующее:
- Создан sklearn-пайплайн для предобработки и создания признаков. На стадии предобработки категориальные признаки преобразованы с помощью OneHotEncoder.<br>
    Для создания новых признаков примененены `QuantileTransformer`, `KBinsDiscretizer` и `PolynomialFeatures`, каждый к определенному набору признаков.
- Сделана автоматическая генерация признаков с помощью библиотеки `autofeat` с применением преобразований `"1/", "log"`.
- Признаки объеденены в общий датафрейм и на нем обучена модель CatBoostRegressor. Оценки модели заметно улучшились по сравнение с baseline.
- Результаты этапа залогированы в MLflow

### Этап 4: Отбор признаков и обучение новой версии модели

В этом разделе мы применили алгоритмы отбора признаков к набору базовых признаков + набору признаков из этапа 3:
- В первую очередь мы отсекли большую часть признаков с помощью алгоритма `SelectFromModel` из библиотеки `sklearn`.
- Затем оставшиеся признаки отфильтровали через алгоритмы `forward feature selection` и `backward feature selection` из библиотеки `mlxtend`. Признаки отобранные обоими алгоритмами были использованы в последующем обучении модели.
- Признаки отобранные обоими алгоритмами из библиотеки `mlxtend` объединены в общий датафрейм и на нем обучена модель CatBoostRegressor. Оценки модели, в этот раз, особо не изменились, по сравнению с предыдущим этапом.
- Результаты этапа залогированы в MLflow

### Этап 5: Подбор гиперпараметров и обучение новой версии модели

На заключительном этапе проекта мы оптимизировали гиперпараметры модели. Использовали несколько методов с помощью библиотеки optuna:
- Первый вариант подбора параметров был запущен с алгоритмом RandomSearch. Запуск, оптимизация и метрики были залогированы с помощью MLflow Callback
- Второй вариант подбора параметров был запущен с байесовским алгоритмом TPE. Запуск, оптимизация и метрики были залогированы с помощью MLflow Callback
- [Сравнили](model_improvement/artif_params_search/mse_search_params.png) работу алгоритмов по подбору параметров, преимущество получил набор параметров для модели от алгоритма TPE, так как показал лучшие значения метрики на валидации. С этим набором параметров была обучена финальная модель и получена оценка на тестовой выборке.
- Результаты этапа залогированы в MLflow

### 6 Анализ результатов.

На этом этапе мы посмотрели на графики изменения метрик в ходе проекта. Метрики улучшились, время обучения модели снизилось!
